{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder/miniconda3/envs/alpa-adaptdl/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-04 12:03:37,008\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-03-04 12:03:39,853\tINFO worker.py:1540 -- Connecting to existing Ray cluster at address: 172.29.14.61:6379...\n",
      "2024-03-04 12:03:39,866\tINFO worker.py:1715 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from orchestrator import Orchestrator\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator = Orchestrator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orchestrator.all_host_num_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator.all_host_num_devices = np.array([4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b0e4bb84-9b8e-4c5f-9cdb-f904958338ed'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orchestrator.register_job()\n",
    "orchestrator.register_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d5284783-3609-4ab8-afad-4bd8650520e3': <pollux_job.PolluxJob at 0x7ffe0ead2b20>,\n",
       " 'b0e4bb84-9b8e-4c5f-9cdb-f904958338ed': <pollux_job.PolluxJob at 0x7ffe0ead2f10>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orchestrator.jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:orchestrator:Waiting for placement group to start.\n",
      "INFO:orchestrator:Placement group has started.\n",
      "INFO:orchestrator:PG table: {'placement_group_id': 'f51dec1f6afe78cad9320037da0036000000', 'name': 'd5284783-3609-4ab8-afad-4bd8650520e3_pg', 'bundles': {0: {'CPU': 1.0, 'GPU': 1.0}}, 'bundles_to_node_id': {0: '30c8a654de19ced690206052390556bdbd769f402d44feda6e48e860'}, 'strategy': 'SPREAD', 'state': 'CREATED', 'stats': {'end_to_end_creation_latency_ms': 2.063, 'scheduling_latency_ms': 1.88, 'scheduling_attempt': 1, 'highest_retry_delay_ms': 0.0, 'scheduling_state': 'FINISHED'}}\n",
      "INFO:orchestrator:Waiting for placement group to start.\n",
      "INFO:orchestrator:Placement group has started.\n",
      "INFO:orchestrator:PG table: {'placement_group_id': '6206b80b4566fa3773ab0999a4ca36000000', 'name': 'b0e4bb84-9b8e-4c5f-9cdb-f904958338ed_pg', 'bundles': {0: {'CPU': 1.0, 'GPU': 1.0}}, 'bundles_to_node_id': {0: '30c8a654de19ced690206052390556bdbd769f402d44feda6e48e860'}, 'strategy': 'SPREAD', 'state': 'CREATED', 'stats': {'end_to_end_creation_latency_ms': 1.732, 'scheduling_latency_ms': 1.628, 'scheduling_attempt': 1, 'highest_retry_delay_ms': 0.0, 'scheduling_state': 'FINISHED'}}\n",
      "INFO:orchestrator:Resource reallocation timer started!\n",
      "INFO:orchestrator:Done reallocating resources\n"
     ]
    }
   ],
   "source": [
    "# request PGs for the jobs\n",
    "\n",
    "for job_id, job in orchestrator.jobs.items():\n",
    "    await orchestrator.initial_request_placement_group(job_id, f\"{job_id}_pg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_power_of_two_combinations(max_gpus):\n",
    "    \"\"\"\n",
    "    Generate all combinations of GPUs allocations in powers of two up to max_gpus.\n",
    "    \"\"\"\n",
    "    return [2**i for i in range(int(np.log2(max_gpus))+1)]\n",
    "    \n",
    "\n",
    "def generate_allocations_for_job(num_nodes, gpus_per_node):\n",
    "    allocations = []\n",
    "    # Single-node allocations\n",
    "    for gpus in generate_power_of_two_combinations(gpus_per_node):\n",
    "        allocations.append((gpus, 1))\n",
    "\n",
    "    # Corrected Multi-node allocations\n",
    "    # The original approach incorrectly represented the total number of GPUs across nodes\n",
    "    # The corrected logic here ensures we represent the number of GPUs per node and the number of nodes accurately\n",
    "    if num_nodes > 1:\n",
    "        for nodes_used in range(2, num_nodes+1):\n",
    "            # Ensure the allocation represents using all GPUs per node for the number of nodes used\n",
    "            allocations.append((gpus_per_node, nodes_used))\n",
    "\n",
    "    return allocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_allocation_valid(combination, num_nodes, gpus_per_node):\n",
    "    # Initialize GPU usage tracking for each node\n",
    "    node_usage = [0] * num_nodes\n",
    "    \n",
    "    for alloc in combination:\n",
    "        gpus, nodes = alloc\n",
    "        if nodes == 1:\n",
    "            # Attempt to allocate on a node with sufficient available GPUs\n",
    "            allocated = False\n",
    "            for i in range(num_nodes):\n",
    "                if node_usage[i] + gpus <= gpus_per_node:\n",
    "                    node_usage[i] += gpus\n",
    "                    allocated = True\n",
    "                    break\n",
    "            if not allocated:\n",
    "                return False\n",
    "        else:\n",
    "            # For multi-node allocations, check if it's possible to allocate across the required nodes\n",
    "            if sum(node_usage) + gpus * nodes > gpus_per_node * num_nodes:\n",
    "                return False\n",
    "            # Simulate allocation across nodes\n",
    "            for i in range(nodes):\n",
    "                node_usage[i] += gpus\n",
    "                \n",
    "    return True\n",
    "\n",
    "def list_possible_allocations(cluster_config, jobs):\n",
    "    num_nodes = len(cluster_config)\n",
    "    gpus_per_node = cluster_config[0]  # Assuming uniform distribution of GPUs across nodes\n",
    "\n",
    "    job_ids = list(jobs.keys())\n",
    "    all_job_allocations = [list(generate_allocations_for_job(num_nodes, gpus_per_node)) for _ in job_ids]\n",
    "\n",
    "    valid_configurations = []\n",
    "    for combination in product(*all_job_allocations):\n",
    "        # Check if the combination is valid by considering flexible node usage\n",
    "        if is_allocation_valid(combination, num_nodes, gpus_per_node):\n",
    "            # Convert the valid combination into the desired dictionary format\n",
    "            config_dict = dict(zip(job_ids, combination))\n",
    "            valid_configurations.append(config_dict)\n",
    "\n",
    "    return valid_configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_config = np.array([4, 4])  # Example cluster configuration\n",
    "# jobs = {'d5284783-3609-4ab8-afad-4bd8650520e3': '<job_object>',\n",
    "#         'b0e4bb84-9b8e-4c5f-9cdb-f904958338ed': '<job_object>'}  # Example job dictionary\n",
    "\n",
    "# cluster_config = np.array([4])  # 1 node, 4 GPUs\n",
    "# jobs = {'1': '<job_object>',\n",
    "#         '2': '<job_object>'}  # 2 jobs\n",
    "\n",
    "# cluster_config = np.array([4])  # 1 node, 4 GPUs\n",
    "# jobs = {'1': '<job_object>',\n",
    "#         '2': '<job_object>',\n",
    "#         '3': '<job_object>'}  # 3 jobs\n",
    "\n",
    "# cluster_config = np.array([4, 2])  # 2 nodes, first with 4 GPUs, second with 2 GPUs\n",
    "# jobs = {'1': '<job_object>',\n",
    "#         '2': '<job_object>'}  # 2 jobs\n",
    "\n",
    "# cluster_config = np.array([4, 4])  # 2 nodes, first with 4 GPUs, second with 2 GPUs\n",
    "# jobs = {'1': '<job_object>'}  # 1 job\n",
    "\n",
    "# cluster_config = np.array([4, 4])  # 2 nodes, 4 GPUs each\n",
    "# jobs = {'1': '<job_object>',\n",
    "#         '2': '<job_object>',\n",
    "#         '3': '<job_object>',\n",
    "#         '4': '<job_object>',\n",
    "#         '5': '<job_object>'}  # 5 jobs\n",
    "\n",
    "# cluster_config = np.array([2, 2, 2, 2])  # 4 nodes, 2 GPUs each\n",
    "# jobs = {'1': '<job_object>',\n",
    "#         '2': '<job_object>'}  # 2 jobs\n",
    "\n",
    "# cluster_config = np.array([4, 4, 4])  # 3 nodes, 4 GPUs each\n",
    "# jobs = {'1': '<job_object>'}  # 1 job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests with a single 4-GPU node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_config = np.array([4])\n",
    "jobs = {'1': '<job_object>',\n",
    "        '2': '<job_object>',\n",
    "        '3': '<job_object>',\n",
    "        '4': '<job_object>'}\n",
    "\n",
    "cluster_config = np.array([4])\n",
    "jobs = {'1': '<job_object>',\n",
    "        '2': '<job_object>',\n",
    "        '3': '<job_object>'}\n",
    "\n",
    "cluster_config = np.array([4])\n",
    "jobs = {'1': '<job_object>',\n",
    "        '2': '<job_object>'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_allocations = list_possible_allocations(cluster_config, jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'1': (1, 1), '2': (1, 1)},\n",
       " {'1': (1, 1), '2': (2, 1)},\n",
       " {'1': (2, 1), '2': (1, 1)},\n",
       " {'1': (2, 1), '2': (2, 1)}]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_allocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "print(generate_power_of_two_combinations(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1), (2, 1), (4, 1), (4, 2)]\n"
     ]
    }
   ],
   "source": [
    "print(generate_allocations_for_job(2, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpa-adaptdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
